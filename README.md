# Predictive Fairness in Healthcare Patient Readmissions
This GitHub repository contains the code and resources related to the Master Thesis project titled "Predictive Fairness in Healthcare Patient Readmissions" by Nikolaos Biniaris, submitted as part of the MSc in Technology and Operations Management at the University of Groningen.

# Project Overview
The project focuses on exploring the concept of equity in hospital decision-making, specifically in predicting patient readmissions in healthcare settings. The research delves into the implications of biases, data imbalances, and underrepresentation in machine learning (ML) models used for clinical predictions.

# Key Concerns:
The growing impact of ML algorithms on decision-making processes raises concerns about potential biases in algorithms.
Unintended biases can lead to unfair discrimination or exacerbate existing inequalities in healthcare.

# Framework Contributions:
Explores sources of bias and their implications in the healthcare ML development cycle.
Introduces methods to handle and quantify various aspects of bias using programming tools.
Provides empirical findings from a hospital readmission prediction model, highlighting biases in imbalanced datasets.
Evaluates various bias mitigation techniques and emphasizes the role of tailored data engineering for effective mitigation.

# Dataset
The research utilizes the "Diabetes 130-Hospitals" dataset sourced from the UCI Machine Learning repository. This dataset comprises ten years of clinical care data from 130 U.S. hospitals, providing a rich foundation for analyzing the impacts of biological attribute handling and data preprocessing on fairness in healthcare predictions.

# Models and Techniques
Various machine learning models (Random Forest, CatBoost, XGBoost) and techniques (Fair AI Tools, xAI Tools and Libraries) were employed to address the challenges of bias mitigation, data imbalance, and fairness in predictive modeling. The study explores the use of tailored data engineering approaches during the preprocessing phase to enhance model accuracy and fairness.

# Results and Findings
The research findings underscore the significance of domain-specific knowledge and insights in developing fair and accurate ML applications in healthcare. By addressing biases and data imbalances through careful data engineering, the study aims to achieve more equitable predictions and outcomes for diverse patient groups.

# Key Learnings
Through experimentation with different bias mitigation approaches and the use of explainable AI (xAI) tools, the project emphasizes the critical role of proper data engineering in mitigating bias, especially in health datasets. The study highlights the importance of gaining domain knowledge and advocating for more diverse and open-source healthcare datasets to improve model accuracy and fairness.
Also, there is a need for more diverse and open-source healthcare datasets.
The ultimate objective is to achieve fair and equitable predictions for all patient groups.

# Acknowledgments
Dr. C. Emmanouilidis and Prof. Dr. I.F.A. Vis for their guidance and support.
Family and friends for their encouragement and belief in the author's potential.
Special thanks to Irene for providing joy and companionship throughout the journey.
For any questions or inquiries, please contact the author at [nikosdbiniaris@yahoo.com].

Thank you for your interest in the "Predictive Fairness in Healthcare Patient Readmissions" project!

# Keywords: 
Fair Machine Learning, Bias Mitigation, Hospital Readmissions, Diabetes Patients, UCI Diabetes Dataset

