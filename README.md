# TOM_Thesis


This work presents a framework for detecting, handling, and mitigating bias in Machine Learning (ML) models used for healthcare clinical predictions, specifically focusing on patient hospital readmissions.

Key Concerns:

The growing impact of ML algorithms on decision-making processes raises concerns about potential biases in algorithms.
Unintended biases can lead to unfair discrimination or exacerbate existing inequalities in healthcare.
Framework Contributions:

Explores sources of bias and their implications in the healthcare ML development cycle.
Introduces methods to handle and quantify various aspects of bias using programming tools.
Provides empirical findings from a hospital readmission prediction model, highlighting biases in imbalanced datasets.
Evaluates various bias mitigation techniques and emphasizes the role of tailored data engineering for effective mitigation.

Outcomes and Future Directions:

This research underscores the importance of:
Domain knowledge acquisition before data engineering.
Availability of more diverse and open-source healthcare datasets.
The ultimate objective is to achieve fair and equitable predictions for all patient groups.

Keywords: Fair Machine Learning, Bias Mitigation, Hospital Readmissions, Diabetes Patients, UCI Diabetes Dataset
finish

Kookie igemasta , ah igempoytzi
